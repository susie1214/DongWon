import pandas as pd
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import json
import os
import re
from dataclasses import dataclass
from typing import Dict, Optional, List
from tqdm import tqdm

# --- 0. 4-bit ì–‘ìí™”ë¥¼ ìœ„í•œ BitsAndBytes ì„¤ì • ---
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)

def load_model_and_tokenizer():
    """LLM ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    if not torch.cuda.is_available():
        raise SystemError("GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 4-bit ì–‘ìí™”ëŠ” GPU í™˜ê²½ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.")
    print(f"âœ… GPU({torch.cuda.get_device_name(0)})ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    model_name = "K-intelligence/Midm-2.0-Mini-Instruct"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    tokenizer.pad_token_id = tokenizer.eos_token_id

    print("\nğŸ”„ 4-bit ì–‘ìí™”ëœ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=quantization_config,
        device_map="auto"
    )
    model.eval()
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    return model, tokenizer

@dataclass
class ProductConfig:
    product_name: str
    features: Optional[str]
    category: Optional[str]
    price: Optional[float]
    base_sales_volume: int

# ì¹´í…Œê³ ë¦¬ë³„ ì»¨í…ìŠ¤íŠ¸ ë° ê³„ì ˆì„± í•¨ìˆ˜
def get_category_context(category: Optional[str]) -> str:
    if not category: return ""
    c = category.lower()
    ctx = []
    ctx.append("- ê³µí†µ: ì„¤(1-2ì›”), ì¶”ì„(9-10ì›”), ì—°ë§(12ì›”)ì€ ì„ ë¬¼ì„¸íŠ¸ ë° ê°€ì •ìš© ìˆ˜ìš”ê°€ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    ctx.append("- í•™ì‚¬ ì¼ì •: 3ì›”(ê°œí•™), 7-8ì›”(ì—¬ë¦„ë°©í•™), 1-2ì›”(ê²¨ìš¸ë°©í•™) ë“±ì€ ê°€ì • ë‚´ ì‹ë£Œí’ˆ ì†Œë¹„ íŒ¨í„´ì— ì˜í–¥ì„ ì¤ë‹ˆë‹¤.")
    if any(k in c for k in ["yogurt", "ìš”ê±°íŠ¸", "ê±´ê°•"]):
        ctx.append("- ê±´ê°• íŠ¸ë Œë“œ: ìƒˆí•´ ê²°ì‹¬(1ì›”), ì—¬ë¦„ ëŒ€ë¹„ ë‹¤ì´ì–´íŠ¸(5-6ì›”) ì‹œì¦Œì— ìˆ˜ìš”ê°€ ì¦ê°€í•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.")
    if any(k in c for k in ["beverage", "drink", "ìŒë£Œ"]):
        ctx.append("- ë‚ ì”¨ ë¯¼ê°ë„: ë¬´ë”ìœ„ê°€ ê¸°ìŠ¹ì„ ë¶€ë¦¬ëŠ” 7-8ì›”ì— ìˆ˜ìš”ê°€ ê¸‰ì¦í•˜ê³ , ì¶”ìš´ 1, 12ì›”ì—ëŠ” ê°ì†Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    return "\n".join(ctx)

def get_category_seasonality(category: Optional[str]) -> Dict[int, float]:
    if not category: return {m: 1.0 for m in range(1, 13)}
    c = category.lower()
    default = {1:1.05, 2:1.08, 3:0.98, 4:0.97, 5:1.02, 6:0.98, 7:1.00, 8:1.02, 9:1.07, 10:1.03, 11:1.02, 12:1.10}
    if any(k in c for k in ["beverage", "drink", "ìŒë£Œ"]):
        default.update({6: 1.15, 7: 1.30, 8: 1.25, 12: 0.85, 1: 0.85})
    return default

month_names = {1: "1ì›”(ê²¨ìš¸)", 2: "2ì›”(ê²¨ìš¸, ì„¤ë‚ )", 3: "3ì›”(ë´„)", 4: "4ì›”(ë´„)", 5: "5ì›”(ë´„, ê°€ì •ì˜ ë‹¬)", 6: "6ì›”(ì—¬ë¦„)", 7: "7ì›”(ì—¬ë¦„, íœ´ê°€ì² )", 8: "8ì›”(ì—¬ë¦„, íœ´ê°€ì² )", 9: "9ì›”(ê°€ì„, ì¶”ì„)", 10: "10ì›”(ê°€ì„)", 11: "11ì›”(ê²¨ìš¸)", 12: "12ì›”(ê²¨ìš¸, ì—°ë§)"}

# 'êµ¬ë§¤ ì˜í–¥ ì ìˆ˜' ì˜ˆì¸¡ í•¨ìˆ˜
def build_score_prediction_prompt(persona: Dict, product: ProductConfig, month: int) -> str:
    category_context = get_category_context(product.category)
    price_info = f"- ê°€ê²©: {product.price:,.0f}ì›" if product.price is not None else "- ê°€ê²©: ì •ë³´ ì—†ìŒ"
    return f"""### ì§ˆë¬¸:
ë‹¹ì‹ ì€ ë‚ ì¹´ë¡œìš´ í†µì°°ë ¥ì„ ì§€ë‹Œ ë§ˆì¼€íŒ… ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ í˜ë¥´ì†Œë‚˜ê°€ ì£¼ì–´ì§„ ì œí’ˆì„ íŠ¹ì • ì‹œì ì— ì–¼ë§ˆë‚˜ êµ¬ë§¤í•˜ê³  ì‹¶ì–´í• ì§€ 'êµ¬ë§¤ ì˜í–¥ ì ìˆ˜'ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.
**1. ë¶„ì„ ëŒ€ìƒ í˜ë¥´ì†Œë‚˜**
{json.dumps(persona, ensure_ascii=False, indent=2)}
**2. êµ¬ë§¤ ê³ ë ¤ ì œí’ˆ**
- ì œí’ˆëª…: {product.product_name}
- ì œí’ˆ íŠ¹ì§•: {product.features or "ì •ë³´ ì—†ìŒ"}
- ì œí’ˆ ìœ í˜•: {product.category or "ì •ë³´ ì—†ìŒ"}
{price_info}
**3. ì‹œì¥ ë° ì‹œì  ì •ë³´**
- êµ¬ë§¤ ì‹œì : **{month_names[month]}**
- ì‹œì¥ ë§¥ë½: {category_context}
**4. ì˜ˆì¸¡ ì§€ì‹œ**
- ìœ„ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬, í˜ë¥´ì†Œë‚˜ì˜ **êµ¬ë§¤ ì˜í–¥ì„ 0ì (ì „í˜€ ê´€ì‹¬ ì—†ìŒ)ë¶€í„° 100ì (ë°˜ë“œì‹œ êµ¬ë§¤)ê¹Œì§€ì˜ ì ìˆ˜**ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.
- ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ì˜¤ì§ **ìˆ«ì(ì •ìˆ˜)**ë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì˜ˆ: `85`
### ë‹µë³€:
"""
def predict_purchase_score(model, tokenizer, prompt: str) -> int:
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    with torch.no_grad():
        outputs = model.generate(**inputs, max_new_tokens=10, eos_token_id=tokenizer.eos_token_id, temperature=0.1)
    response_text = tokenizer.decode(outputs[0], skip_special_tokens=True).split("### ë‹µë³€:")[-1]
    try:
        numbers = re.findall(r'\d+', response_text)
        score = int(numbers[0]) if numbers else 50
        return max(0, min(100, score))
    except (ValueError, IndexError):
        return 50

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # --- 1. ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ ---
    model, tokenizer = load_model_and_tokenizer()
    
    data_path = './'
    product_df = pd.read_csv(os.path.join(data_path, 'product_info.csv'))
    submission_df = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'))

    # --- 2. ì €ì¥ëœ í˜ë¥´ì†Œë‚˜ ë¡œë“œ ---
    b2c_personas_path = 'b2c_personas.json'
    b2b_personas_path = 'b2b_personas.json'

    if not os.path.exists(b2c_personas_path) or not os.path.exists(b2b_personas_path):
        print("\nâŒ í˜ë¥´ì†Œë‚˜ íŒŒì¼(.json)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € `generate_personas.py`ë¥¼ ì‹¤í–‰í•˜ì—¬ í˜ë¥´ì†Œë‚˜ íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return

    print(f"\nâœ… '{b2c_personas_path}'ì™€ '{b2b_personas_path}' íŒŒì¼ì—ì„œ í˜ë¥´ì†Œë‚˜ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.")
    with open(b2c_personas_path, 'r', encoding='utf-8') as f:
        fixed_b2c_personas = json.load(f)
    with open(b2b_personas_path, 'r', encoding='utf-8') as f:
        fixed_b2b_personas = json.load(f)

    # --- 3. ìˆ˜ìš”ëŸ‰ ì˜ˆì¸¡ ---
    print("\n--- ğŸš€ ìˆ˜ìš”ëŸ‰ ì˜ˆì¸¡ì„ ì‹œì‘í•©ë‹ˆë‹¤ ---")
    all_predictions = []
    all_personas = fixed_b2c_personas + fixed_b2b_personas
    np.random.seed(42)

    for _, product_row in tqdm(product_df.iterrows(), total=len(product_df), desc="ğŸ“¦ ì „ì²´ ì œí’ˆ ì˜ˆì¸¡ ì§„í–‰"):
        product_info = ProductConfig(
            product_name=product_row['product_name'],
            features=product_row.get('product_feature'),
            category=product_row.get('category_level_1'),
            price=float(product_row['price']) if 'price' in product_row and pd.notna(product_row['price']) else None,
            base_sales_volume=int(product_row['base_units']) if 'base_units' in product_row and pd.notna(product_row['base_units']) else 5000
        )
        monthly_total_volumes = []
        seasonality = get_category_seasonality(product_info.category)

        for m in range(1, 13):
            prompts = [build_score_prediction_prompt(p, product_info, m) for p in all_personas]
            all_scores = [predict_purchase_score(model, tokenizer, p) for p in prompts]
            
            average_score = np.mean(all_scores) if all_scores else 50
            base_quantity = product_info.base_sales_volume * (average_score / 50.0)
            seasonal_multiplier = seasonality.get(m, 1.0)
            noise = np.random.normal(1.0, 0.05)
            final_quantity = base_quantity * seasonal_multiplier * noise
            monthly_total_volumes.append(int(round(max(0, final_quantity))))

        all_predictions.append([product_info.product_name] + monthly_total_volumes)

    # --- 4. ì œì¶œ íŒŒì¼ ìƒì„± ---
    prediction_output = pd.DataFrame(all_predictions, columns=submission_df.columns)
    submission_path = 'final_submission.csv'
    prediction_output.to_csv(submission_path, index=False)
    print(f"\n\nğŸ‰ ì˜ˆì¸¡ ì™„ë£Œ! ìµœì¢… ê²°ê³¼ê°€ '{submission_path}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(prediction_output.head())

if __name__ == "__main__":
    main()
